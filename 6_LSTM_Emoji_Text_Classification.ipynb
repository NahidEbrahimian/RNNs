{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1frSvdgmaJ7"
   },
   "source": [
    "Special thanks to Alireza Akhavan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BM05GpttQV5K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSJIptosmunz"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81ZusynzQV5L"
   },
   "source": [
    "Dataset EMOJISET\n",
    "\n",
    "You have a tiny dataset (X, Y) where:\n",
    "- X contains 127 sentences (strings)\n",
    "- Y contains a integer label between 0 and 4 corresponding to an emoji for each sentence\n",
    "\n",
    "<img src=\"https://github.com/Alireza-Akhavan/rnn-notebooks/blob/master/images/data_set.png?raw=1\" style=\"width:700px;height:300px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAHEMD99QV5M"
   },
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    data_frame = pd.read_csv(filename)\n",
    "    X = np.asarray(data_frame[\"sentence\"])\n",
    "    Y = np.asarray(data_frame[\"label\"], dtype=int)\n",
    "    return X, Y\n",
    "\n",
    "X_train, Y_train = read_csv('datasets/Emoji_Text_Classification/train.csv')\n",
    "X_test, Y_test = read_csv('datasets/Emoji_Text_Classification/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kb0ARa9ZQV5N",
    "outputId": "24e71a84-ea73-48f0-dbbf-9adb4e19702d"
   },
   "outputs": [],
   "source": [
    "max_len = len(max(X_train, key=len).split())  # length of the largest sentence\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2kRqG3qSQV5O"
   },
   "outputs": [],
   "source": [
    "def label_to_emoji(label):\n",
    "    emojies = [\"‚ù§Ô∏è\", \"üèê\", \"üòÑ\", \"üòû\", \"üç¥\"]\n",
    "    return emojies[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2lhFyt9QV5O",
    "outputId": "69313cd4-54bd-435f-a486-cd9eb628ff7b"
   },
   "outputs": [],
   "source": [
    "index = 7\n",
    "print(X_train[index], label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQd3aUWionKW"
   },
   "source": [
    "## Emojifier-V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiTKA--IQV5P"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://github.com/Alireza-Akhavan/rnn-notebooks/blob/master/images/image_1.png?raw=1\" style=\"width:900px;height:300px;\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZyZ9yRwDQV5P"
   },
   "outputs": [],
   "source": [
    "# convert labels to one hot\n",
    "Y_train_oh = tf.keras.utils.to_categorical(Y_train, 5)\n",
    "Y_test_oh = tf.keras.utils.to_categorical(Y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SBwsX6HHQV5P",
    "outputId": "a354602e-3230-455c-b26a-82f69974d4c0"
   },
   "outputs": [],
   "source": [
    "index = 7\n",
    "print(Y_train[index], \"is converted into one hot\", Y_train_oh[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMzm68jkZVqw"
   },
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip --no-verbose\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pog8XGg9QV5Q"
   },
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, encoding=\"utf8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        words_to_index = {}\n",
    "        for i, w in enumerate(sorted(words)):\n",
    "            words_to_index[w] = i + 1\n",
    "\n",
    "    return words_to_index, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxWLt4nOQV5Q"
   },
   "outputs": [],
   "source": [
    "word_to_index, word_to_vec_map = read_glove_vecs('glove.6B/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUTkM7-zQV5Q",
    "outputId": "1c33be89-9e15-4388-8ecd-fafadc8b4c96"
   },
   "outputs": [],
   "source": [
    "word_to_index[\"ali\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SeQOWLsPQV5Q",
    "outputId": "7c067ef9-aae0-4667-de76-84fbdf7a622e"
   },
   "outputs": [],
   "source": [
    "word_to_vec_map[\"ali\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qONTUGu2QV5R"
   },
   "outputs": [],
   "source": [
    "# convert sentence to average of the word vectors\n",
    "def sentence_to_avg(sentence):\n",
    "    words = sentence.lower().split()\n",
    "    sum_vectors = np.zeros((50,))\n",
    "    for w in words:\n",
    "        sum_vectors += word_to_vec_map[w] \n",
    "    \n",
    "    avg_vectors = sum_vectors / len(words)\n",
    "    return avg_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFKeySSWQV5R",
    "outputId": "c60783f9-763a-4c62-c7cb-e30ccf403117",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence_to_avg(\"Pasta is my favorite food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dcoXzn1jjte"
   },
   "outputs": [],
   "source": [
    "X_train_avg = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train_avg.append(sentence_to_avg(X_train[i]))\n",
    "\n",
    "X_train_avg = np.array(X_train_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VD2hx3yklPzl",
    "outputId": "af8970bf-942e-473a-d2a3-1706938fdb15"
   },
   "outputs": [],
   "source": [
    "print(X_train_avg.shape)\n",
    "print(Y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBBPmlRHityO"
   },
   "outputs": [],
   "source": [
    "class EmojiNet_V1(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense = Dense(5, input_shape=(50,), activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfDWrLrBjDeg"
   },
   "outputs": [],
   "source": [
    "model = EmojiNet_V1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnFHWaJ-jCz_"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7sKIc5bEQV5R",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_avg, Y_train_oh, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkYS1JiNlpju"
   },
   "outputs": [],
   "source": [
    "X_test_avg = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_avg.append(sentence_to_avg(X_test[i]))\n",
    "\n",
    "X_test_avg = np.array(X_test_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hLi0N9QQV5S",
    "outputId": "c662dd2c-0790-4fd9-a7de-946b8ef8e4ee"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test_avg, Y_test_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiIeOyV0QV5U"
   },
   "source": [
    "Random guessing would have had 20% accuracy given that there are 5 classes. This is pretty good performance after training on only 132 examples. \n",
    "\n",
    "In the training set, the algorithm saw the sentence \"*I love you*\" with the label ‚ù§Ô∏è. You can check however that the word \"adore\" does not appear in the training set. Nonetheless, lets see what happens if you write \"*I adore you*.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ky7r1CC9QV5U",
    "outputId": "ec062512-59ad-4d38-c1b7-38ee137b9360"
   },
   "outputs": [],
   "source": [
    "X_me = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "Y_me = np.array([[0], [0], [2], [1], [4], [3]])\n",
    "\n",
    "X_me_avg = []\n",
    "for x in X_me:\n",
    "    X_me_avg.append(sentence_to_avg(x))\n",
    "X_me_avg = np.array(X_me_avg)\n",
    "\n",
    "pred = model.predict(X_me_avg)\n",
    "\n",
    "for i in range(X_me.shape[0]):\n",
    "    print(X_me[i], label_to_emoji(np.argmax(pred[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwZVvKOiQV5U"
   },
   "source": [
    "Amazing! Because *adore* has a similar embedding as *love*, the algorithm has generalized correctly even to a word it has never seen before. Words such as *heart*, *dear*, *beloved* or *adore* have embedding vectors similar to *love*, and so might work too.\n",
    "\n",
    "feel free to modify the inputs above and try out a variety of input sentences. How well does it work?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VcP5QlyQV5U"
   },
   "source": [
    "## Emojifier-V2: Using RNNs: \n",
    "\n",
    "Let's build an LSTM model that takes as input word sequences. This model will be able to take word ordering into account. Emojifier-V2 will continue to use pre-trained word embeddings to represent words, but will feed them into an LSTM, whose job it is to predict the most appropriate emoji. \n",
    "\n",
    "Run the following cell to load the Keras packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilHTolRmQV5V"
   },
   "source": [
    "<img src=\"https://github.com/Alireza-Akhavan/rnn-notebooks/blob/master/images/emojifier-v2.png?raw=1\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center> **Figure 3**: Emojifier-V2. A 2-layer LSTM sequence classifier. </center></caption>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rwk081qeQV5V"
   },
   "source": [
    "<img src=\"https://github.com/Alireza-Akhavan/rnn-notebooks/blob/master/images/embedding1.png?raw=1\" style=\"width:700px;height:250px;\">\n",
    "<caption><center> **Figure 4**: Embedding layer. This example shows the propagation of two examples through the embedding layer. Both have been zero-padded to a length of `max_len=5`. The final dimension of the representation is  `(2,max_len,50)` because the word embeddings we are using are 50 dimensional. </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentences_to_embeddings(X):\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
    "\n",
    "    emb_matrix = np.zeros((X.shape[0], max_len, emb_dim))\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        words = X[i].lower().split()\n",
    "        for j in range(len(words)):\n",
    "            emb_matrix[i, j, :] = word_to_vec_map[words[j]]\n",
    "    \n",
    "    return emb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vz3mnf8XQV5V",
    "outputId": "a351fc82-5699-46a2-feea-5f48ff49666d"
   },
   "outputs": [],
   "source": [
    "X_me = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "print(X_me)\n",
    "print(convert_sentences_to_embeddings(X_me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embs = convert_sentences_to_embeddings(X_train)\n",
    "X_train_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_oh = tf.keras.utils.to_categorical(Y_train, 5)\n",
    "Y_train_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onQHnqBLQV5W"
   },
   "outputs": [],
   "source": [
    "class EmojiNet_V2(Model):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm_1 = LSTM(128, return_sequences=True)\n",
    "        self.dropout_1 = Dropout(0.5)\n",
    "        self.lstm_2 = LSTM(128)\n",
    "        self.dropout_2 = Dropout(0.5)\n",
    "        self.dense = Dense(5, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.lstm_1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.lstm_2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fcDh2-DhV6p"
   },
   "outputs": [],
   "source": [
    "model = EmojiNet_V2((max_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9JANdx8fQV5W"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlkmi826QV5W",
    "outputId": "737d1896-c4e8-434f-b6d5-59334732a246"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJgwtY1AQV5W"
   },
   "source": [
    "It's time to train your model. Your Emojifier-V2 `model` takes as input an array of shape (`m`, `max_len`) and outputs probability vectors of shape (`m`, `number of classes`). We thus have to convert X_train (array of sentences as strings) to X_train_indices (array of sentences as list of word indices), and Y_train (labels as indices) to Y_train_oh (labels as one-hot vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peGMLN0BQV5W",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(emb_matrix, Y_train_oh, epochs=50, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhCfmdnFQV5X"
   },
   "source": [
    "Your model should perform close to **100% accuracy** on the training set. The exact accuracy you get may be a little different. Run the following cell to evaluate your model on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWpVyPhoQV5X",
    "outputId": "a61547aa-e165-4959-b27c-bacce1d6b9b3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_embs = convert_sentences_to_embeddings(X_test)\n",
    "Y_test_oh = tf.keras.utils.to_categorical(Y_test, 5)\n",
    "model.evaluate(X_test_embs, Y_test_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTEztaS_QV5X"
   },
   "source": [
    "You should get a test accuracy between 80% and 95%. Run the cell below to see the mislabelled examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-WxHumJQV5X",
    "outputId": "ba64b6da-29d1-49e8-c14d-8cd53e42c650"
   },
   "outputs": [],
   "source": [
    "# This code allows you to see the mislabelled examples\n",
    "\n",
    "pred = model.predict(X_test_embs)\n",
    "for i in range(len(X_test)):\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != Y_test[i]):\n",
    "        print('Expected emoji:', label_to_emoji(Y_test[i]), 'prediction:', X_test[i], label_to_emoji(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGMsFfRZQV5X"
   },
   "source": [
    "Now you can try it on your own example. Write your own sentence below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ltzedF3QV5X",
    "outputId": "2cfb01b3-b5ba-4da6-ffa3-1323acebbaa8"
   },
   "outputs": [],
   "source": [
    "# Change the sentence below to see your prediction. Make sure all the words are in the Glove embeddings.  \n",
    "x_me = np.array(['not feeling happy'])\n",
    "X_me_embs = convert_sentences_to_embeddings(x_me)\n",
    "pred = model.predict(X_me_embs)\n",
    "print(x_me[0], label_to_emoji(np.argmax(pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCmyeW67QV5X"
   },
   "source": [
    "Previously, Emojify-V1 model did not correctly label \"not feeling happy,\" but our implementation of Emojiy-V2 got it right. (Keras' outputs are slightly random each time, so you may not have obtained the same result.) The current model still isn't very robust at understanding negation (like \"not happy\") because the training set is small and so doesn't have a lot of examples of negation. But if the training set were larger, the LSTM model would be much better than the Emojify-V1 model at understanding such complex sentences. \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ilHTolRmQV5V"
   ],
   "name": "07_text-classification-Emojify.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "RNnEs",
   "launcher_item_id": "acNYU"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
